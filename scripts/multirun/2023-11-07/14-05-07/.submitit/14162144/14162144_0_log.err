GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/icb/alessandro.palma/miniconda3/envs/IMPA/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py:72: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.
wandb: Currently logged in as: allepalma. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.15.12
wandb: Run data is saved locally in ../project_folder/experiments/20231107_bbbc021_try/wandb/run-20231107_140522-udj35pwu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-puddle-38
wandb: ‚≠êÔ∏è View project at https://wandb.ai/allepalma/bbbc021_try
wandb: üöÄ View run at https://wandb.ai/allepalma/bbbc021_try/runs/udj35pwu

  | Name             | Type         | Params
--------------------------------------------------
0 | embedding_matrix | Embedding    | 960   
1 | generator        | DataParallel | 24.3 M
2 | style_encoder    | DataParallel | 14.3 M
3 | discriminator    | DataParallel | 14.3 M
4 | mapping_network  | DataParallel | 11.3 K
--------------------------------------------------
53.0 M    Trainable params
960       Non-trainable params
53.0 M    Total params
211.840   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
slurmstepd: error: *** JOB 14162144 ON gpusrv59 CANCELLED AT 2023-11-07T14:13:21 ***
slurmstepd: error: *** STEP 14162144.0 ON gpusrv59 CANCELLED AT 2023-11-07T14:13:21 ***
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
[rank: 0] Received SIGTERM: 15
Bypassing SIGTERM: 15
submitit WARNING (2023-11-07 14:13:25,291) - Bypassing signal SIGTERM
submitit WARNING (2023-11-07 14:13:25,294) - Bypassing signal SIGCONT
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:       D/latent_fake ‚ñÅ
wandb:       D/latent_real ‚ñÅ
wandb:        D/latent_reg ‚ñÅ
wandb:         G/lambda_ds ‚ñÅ
wandb:        G/latent_adv ‚ñÅ
wandb:        G/latent_cyc ‚ñÅ
wandb:         G/latent_ds ‚ñÅ
wandb:        G/latent_sty ‚ñÅ
wandb:               epoch ‚ñÅ
wandb: trainer/global_step ‚ñÅ
wandb: 
wandb: Run summary:
wandb:       D/latent_fake 1.15704
wandb:       D/latent_real 0.10718
wandb:        D/latent_reg 0.00177
wandb:         G/lambda_ds 0.9999
wandb:        G/latent_adv 1.27594
wandb:        G/latent_cyc 0.80055
wandb:         G/latent_ds 0.54841
wandb:        G/latent_sty 0.95715
wandb:               epoch 0
wandb: trainer/global_step 9
wandb: 
wandb: üöÄ View run morning-puddle-38 at: https://wandb.ai/allepalma/bbbc021_try/runs/udj35pwu
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ../project_folder/experiments/20231107_bbbc021_try/wandb/run-20231107_140522-udj35pwu/logs
