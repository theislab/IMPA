{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "356d54f9-cda9-4af6-9637-fe552df4c25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "2872f1e8-cffb-4d9c-bb64-52fd3ba2fc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "# Define logistic regression model using PyTorch Lightning\n",
    "# class LogisticRegressionModel(pl.LightningModule):\n",
    "#     def __init__(self, input_dim, output_dim):\n",
    "#         super(LogisticRegressionModel, self).__init__()\n",
    "#         self.linear = nn.Linear(input_dim, output_dim)\n",
    "#         self.criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         return torch.softmax(self.linear(x), dim=1)\n",
    "    \n",
    "#     def training_step(self, batch, batch_idx):\n",
    "#         x, y = batch\n",
    "#         y_hat = self(x)\n",
    "#         loss = self.criterion(y_hat, y)\n",
    "#         self.log('train_loss', loss)\n",
    "#         return loss\n",
    "\n",
    "#     def test_step(self, batch, batch_idx):\n",
    "#         x, y = batch\n",
    "#         y_hat = self(x)\n",
    "#         predicted = torch.argmax(y_hat, 1)\n",
    "#         accuracy = (predicted == y).sum().item() / len(y)\n",
    "#         self.log('test_accuracy', accuracy, on_epoch=True)\n",
    "#         return accuracy\n",
    "\n",
    "#     def configure_optimizers(self):\n",
    "#         return torch.optim.Adam(self.parameters(), lr=0.01)\n",
    "\n",
    "class LogisticRegressionModel(pl.LightningModule):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, output_dim)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.softmax(x, dim=1)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        _, predicted = torch.max(y_hat, 1)\n",
    "        accuracy = (predicted == y).sum().item() / len(y)\n",
    "        self.log('test_accuracy', accuracy, on_epoch=True)\n",
    "        return accuracy\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ec01d91b-95f1-4ee8-8b77-5b4b7762a2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dest_folder = Path(\"/home/icb/alessandro.palma/environment/IMPA/IMPA/project_folder/dino_featurization_project/featurized_anndata/rxrx1\")\n",
    "adata_after_transf = sc.read_h5ad(feature_dest_folder / \"rxrx1_adata_after_transf.h5ad\")\n",
    "adata_before_transf = sc.read_h5ad(feature_dest_folder / \"rxrx1_adata_before_transf.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584d4aa6-cd7e-407b-b4d1-fa6eebe60352",
   "metadata": {},
   "source": [
    "Add compounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d806524a-1c9f-407d-a947-36727342a873",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_index = pd.read_csv('/home/icb/alessandro.palma/environment/IMPA/IMPA/project_folder/datasets/rxrx1/metadata/rxrx1_df.csv', index_col=1)\n",
    "\n",
    "compound_names = []\n",
    "\n",
    "for row in adata_before_transf.obs.iterrows():\n",
    "    batch = row[1].batch\n",
    "    plate = row[1].plate\n",
    "    well = row[1].well\n",
    "    view = row[1][\"view\"]\n",
    "    no = row[1].no\n",
    "    file_name = f\"U2OS-{batch}_{plate}_{well}_{view}_{no}\"\n",
    "    cpd = data_index.loc[file_name].CPD_NAME\n",
    "    compound_names.append(cpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "57544131-2d9d-4f83-b581-234909b0a76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_after_transf.obs[\"compound\"] = compound_names\n",
    "adata_before_transf.obs[\"compound\"] = compound_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d81e3d-32d3-4467-88f5-dcbfb9260eb2",
   "metadata": {},
   "source": [
    "## BEFORE correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "393343ad-b269-4a17-a1b7-f59bcd12d4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_before = adata_before_transf.X.copy()\n",
    "y_before = np.array(compound_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "daf070d2-c915-4823-a1a1-c115d291784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder_before = LabelEncoder()\n",
    "y_before = label_encoder_before.fit_transform(y_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "8b0afe17-b312-4090-8fdb-8db3f7006960",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_before, X_test_before, y_train_before, y_test_before = train_test_split(X_before, \n",
    "                                                                                y_before, \n",
    "                                                                                test_size=0.2,\n",
    "                                                                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "802f3234-52f8-47fa-bc4a-d22e5ba3a1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor_before = torch.tensor(X_train_before, dtype=torch.float32)\n",
    "y_train_tensor_before = torch.tensor(y_train_before, dtype=torch.long)\n",
    "X_test_tensor_before = torch.tensor(X_test_before, dtype=torch.float32)\n",
    "y_test_tensor_before = torch.tensor(y_test_before, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "06dca168-709b-4845-acb6-c1dd6e507840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for batching\n",
    "train_data_before = TensorDataset(X_train_tensor_before, y_train_tensor_before)\n",
    "train_loader_before = DataLoader(train_data_before, batch_size=256, shuffle=True, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "660ad233-c552-40c9-99fe-d2427bfcf10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icb/alessandro.palma/miniconda3/envs/IMPA_try/lib/python3.9/site-packages/lightning_fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3.9 /home/icb/alessandro.palma/miniconda3/envs/IMPA_t ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/icb/alessandro.palma/miniconda3/envs/IMPA_try/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:630: Checkpoint directory /ictstr01/home/icb/alessandro.palma/environment/IMPA/IMPA/notebooks/cpg0000/lightning_logs/version_18688408/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | fc1       | Linear           | 24.6 K\n",
      "1 | fc2       | Linear           | 2.1 K \n",
      "2 | fc3       | Linear           | 35.3 K\n",
      "3 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "62.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "62.1 K    Total params\n",
      "0.248     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.010017871856689453,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "194df728fdf141509cf8e02b4d2fa893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Lightning model\n",
    "input_dim_before = X_train_before.shape[1]\n",
    "output_dim_before = len(np.unique(compound_names))\n",
    "model_before = LogisticRegressionModel(input_dim_before, output_dim_before)\n",
    "\n",
    "# Train the Lightning model\n",
    "trainer_before = pl.Trainer(max_epochs=100)\n",
    "trainer_before.fit(model_before, train_loader_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "28185c28-5346-4aef-9937-ad2f3e8e4a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icb/alessandro.palma/miniconda3/envs/IMPA_try/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "Restoring states from the checkpoint path at /ictstr01/home/icb/alessandro.palma/environment/IMPA/IMPA/notebooks/cpg0000/lightning_logs/version_18688408/checkpoints/epoch=99-step=53500-v2.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /ictstr01/home/icb/alessandro.palma/environment/IMPA/IMPA/notebooks/cpg0000/lightning_logs/version_18688408/checkpoints/epoch=99-step=53500-v2.ckpt\n",
      "/home/icb/alessandro.palma/miniconda3/envs/IMPA_try/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=5` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.005232810974121094,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Testing",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ad6dbc1155a4c96a8f564059bd5666c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.0005849834997206926   </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0005849834997206926  \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data_before = TensorDataset(X_test_tensor_before, y_test_tensor_before)\n",
    "test_loader_before = DataLoader(test_data_before, batch_size=32)\n",
    "test_results_before = trainer_before.test(dataloaders=test_loader_before)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4761cc38-5d56-423a-9cec-fd707bcdf247",
   "metadata": {},
   "source": [
    "## AFTER correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "088812ec-b906-4a50-a03d-4b7876890e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_after = adata_after_transf.X.copy()\n",
    "y_after = np.array(compound_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "feea0f3d-f1b0-43c7-a463-a5ef6c585fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder_after = LabelEncoder()\n",
    "y_after = label_encoder_after.fit_transform(y_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "650f73a8-751a-4aaf-bd54-cf499e9cfdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_after, X_test_after, y_train_after, y_test_after = train_test_split(X_after, \n",
    "                                                                            y_after, \n",
    "                                                                            test_size=0.2,\n",
    "                                                                            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "be2c351f-20f6-41bd-ad53-236f992fe66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor_after = torch.tensor(X_train_after, dtype=torch.float32)\n",
    "y_train_tensor_after = torch.tensor(y_train_after, dtype=torch.long)\n",
    "X_test_tensor_after = torch.tensor(X_test_after, dtype=torch.float32)\n",
    "y_test_tensor_after = torch.tensor(y_test_after, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "3c4514eb-078f-4c6b-a658-3461cdf4a427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for batching\n",
    "train_data_after = TensorDataset(X_train_tensor_after, y_train_tensor_after)\n",
    "train_loader_after = DataLoader(train_data_after, batch_size=512, shuffle=True, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "c453feed-97c9-4c6c-9791-a00b83de6993",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | fc1       | Linear           | 24.6 K\n",
      "1 | fc2       | Linear           | 2.1 K \n",
      "2 | fc3       | Linear           | 35.3 K\n",
      "3 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "62.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "62.1 K    Total params\n",
      "0.248     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.009514570236206055,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47df29ccc7bf4d67940f93a0303e0878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Lightning model\n",
    "input_dim_after = X_train_after.shape[1]\n",
    "output_dim_after = len(np.unique(compound_names))\n",
    "model_after = LogisticRegressionModel(input_dim_after, output_dim_after)\n",
    "\n",
    "# Train the Lightning model\n",
    "trainer_after = pl.Trainer(max_epochs=100)\n",
    "trainer_after.fit(model_after, train_loader_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "7cb4fe51-d5e5-41d4-b00e-80b0c732f57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /ictstr01/home/icb/alessandro.palma/environment/IMPA/IMPA/notebooks/cpg0000/lightning_logs/version_18688408/checkpoints/epoch=99-step=26800-v2.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /ictstr01/home/icb/alessandro.palma/environment/IMPA/IMPA/notebooks/cpg0000/lightning_logs/version_18688408/checkpoints/epoch=99-step=26800-v2.ckpt\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.008055686950683594,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Testing",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01fe040d6df44425be484b5718512159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.004328877665102482    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.004328877665102482   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data_after = TensorDataset(X_test_tensor_after, y_test_tensor_after)\n",
    "test_loader_after = DataLoader(test_data_after, batch_size=32)\n",
    "test_results_after = trainer_after.test(dataloaders=test_loader_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072abbd8-3973-4fc5-b123-0f8145369b41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52929a10-2e77-4b89-81ba-9a0299697656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f882cffa-edcd-456f-8c73-b4e4fd2dbf2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce765812-cf5a-4a52-92af-bbd11545b93e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
